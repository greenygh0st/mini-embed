# ğŸ§  Mini Embed Server

A lightweight, containerized embedding API that runs locally using [sentence-transformers](https://www.sbert.net/). Designed to power semantic search and retrieval-augmented generation (RAG) pipelines **without relying on OpenAI or external APIs**.

---

## ğŸš€ Features

- Runs locally via Flask + Docker
- Uses the `all-MiniLM-L6-v2` model (384-dim embeddings)
- Accepts text over HTTP and returns vector embeddings
- CPU-friendly â€” no GPU required
- Built-in request logging to STDOUT

---

## ğŸ“¦ Requirements

- Docker
- Python (for local testing without Docker)

---

## ğŸ”§ Quick Start

### â–¶ï¸ Build and run with Docker

```bash
docker build -t mini-embed-server .
docker run -d -p 5000:5000 --name mini-embed-server mini-embed-server
```

### ğŸ“¡ Test the API

```bash
curl -X POST http://localhost:5000/embed \
     -H "Content-Type: application/json" \
     -d '{"text": "How do I reset my password?"}'
```

---

## ğŸ”„ API

### `POST /embed`

**Request Body:**
```json
{
  "text": "Your input text goes here"
}
```

**Response:**
```json
{
  "embedding": [0.123, -0.456, ...]
}
```

---

## ğŸ” Use Cases

- Semantic search with PGVector
- Local RAG pipelines
- Embedding indexing for internal documents
- Offline language understanding

---

## ğŸ› ï¸ Configuration

By default, the server listens on:

```
Host: 0.0.0.0
Port: 5000
```

Edit `embed_server.py` to change the model or port.

---

## ğŸ§ª Development (without Docker)

```bash
pip install flask sentence-transformers
python embed_server.py
```

---

## ğŸ“ License

MIT or similar â€” use freely, modify as needed.

---

## âœ¨ Inspired By

- [sentence-transformers](https://github.com/UKPLab/sentence-transformers)
- OpenAI Embeddings â€” but free and local